{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Simple LLM Calls - SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your first hands-on experience with Large Language Models! \n",
    "\n",
    "In this exercise, you'll learn how to interact with an LLM programmatically using the OpenAI SDK. This is your gateway to building applications that harness the power of AI for generating text, automating tasks, and solving complex problems. Whether you're aiming to integrate AI into a product or just exploring its potential, this exercise will give you the foundational skills to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "You are tasked with creating an application that helps Marketing Analysts with creating content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"voc-\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define important parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To effectively call the API, it's important to define some important parameters.\n",
    "- model: the specific LLM you want to call. We'll be using gpt-4o-mini.\n",
    "- temperature: how random you want the responses to be. It ranges from 0.0 to 1.0. Values more close to 1.0 let the LLM be more creative, while values close to 0.0 let it be more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tell the model how to behave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most powerful parameter is system prompt. It enables you to instruct how you want the LLM to behave. It's important to write a clear, concise instruction for the LLM.\n",
    "\n",
    "Suppose you work for a fictitious B2B company which developed a benefits card for companies to offer their employees more cultural experiences, such as Museums, Art Galleries, Concerts, etc.\n",
    "\n",
    "- For this exercise, the prompt should be specific enough to guide the LLM towards the desired output (B2B content about CultPass)\n",
    "- But also flexible enough to handle a range of industries (target) and channels (email, instagram, tiktok...)\n",
    "\n",
    "Example:\n",
    "```python\n",
    "system_prompt = \"Act as a B2B content creator for a company called CultPass.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Act as a B2B content creator.\n",
    "Create marketing campaign texts to reach the audience of the company CultPass,\n",
    "which has developed a benefits card for companies to offer their employees more culture, \n",
    "such as museums, art galleries, concerts, and similar experiences.\n",
    "Do not provide any explanations, only the material to be sent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a function to reuse LLM calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have all the parameters, you need to accept the user input to send to OpenAI API.\n",
    "\n",
    "To accept it, add a new element to the `messages` list inside the `create_content` function. It's a dictionary similar to the first element, but this time the role is `user`.\n",
    "\n",
    "Remember, the structure is the following:\n",
    "```python\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Act as a Fintech Analyst\"},\n",
    "            {\"role\": \"user\", \"content\": \"What's a credit card fraud?\"},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "print(response.choices[0].message.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_content(query:str,\n",
    "                   client:OpenAI, \n",
    "                   system_prompt:str,\n",
    "                   model:str,\n",
    "                   temperature:float)->str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    # Experiment returning the full response to understand the object\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Call `create_content` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marketing Analyst input\n",
    "analyst_query = \"Create an instagram post for clients in the automotive industry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = create_content(\n",
    "    query=analyst_query,\n",
    "    client=client,\n",
    "    system_prompt=system_prompt,\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**üì∏ [Image of a vibrant art gallery filled with people enjoying an exhibit]**\n",
      "\n",
      "**Caption:**\n",
      "\n",
      "üöó‚ú® Elevate your team‚Äôs experience beyond the assembly line! With CultPass, empower your employees to explore the world of culture‚Äîmuseums, art galleries, concerts, and more‚Äîall while boosting morale and creativity. \n",
      "\n",
      "üåü Why choose CultPass for your automotive company? \n",
      "\n",
      "1Ô∏è‚É£ **Inspire Innovation**: Exposure to art and culture fuels creativity, leading to groundbreaking ideas in design and engineering.  \n",
      "2Ô∏è‚É£ **Boost Team Morale**: A happy employee is a productive employee. Give your team the chance to unwind and recharge.  \n",
      "3Ô∏è‚É£ **Strengthen Company Culture**: Show your commitment to employee well-being and foster a sense of community within your organization.\n",
      "\n",
      "üîë Unlock a world of cultural experiences for your team today! \n",
      "\n",
      "üëâ DM us to learn how CultPass can transform your workplace culture. \n",
      "\n",
      "#CultPass #AutomotiveIndustry #EmployeeBenefits #CulturalExperiences #TeamInspiration #BoostMorale #CompanyCulture #ArtAndInnovation\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understood how it works, experiment with new things.\n",
    "\n",
    "- Change the temperature of the model\n",
    "- Change the system prompt\n",
    "- Change the user query to other channels and industries\n",
    "- Inspect the objects returned by OpenAI, what else you can get out of it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
