{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Simple LLM Calls - STARTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will apply your skills to call an LLM programmatically using OpenAI sdk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "In this exercise, you are tasked with creating an application that helps Marketing Analysts with creating content.\n",
    "\n",
    "You all work for CultPass, a fictitious B2B company which developed a benefits card for companies to offer their employees more cultural experiences, such as Museums, Art Galleries, Concerts, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"sk-\")\n",
    "```\n",
    "Usually the OpenAI API key is a long string starting with `sk-`.\n",
    "\n",
    "\n",
    "Alternatively, can do this implicitly. However to use this approach, you should have a .env file with a variable called OPENAI_API_KEY.\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "```\n",
    "\n",
    "Loading an environment variable prevents you from exposing it in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FILL IN - Instantiate your client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define important parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To effectively call the API, it's important to define some important parameters.\n",
    "- model: the specific LLM you want to call. We'll be using gpt-4o-mini.\n",
    "- temperature: how random you want the responses to be. It ranges from 0.0 to 1.0. Values more close to 1.0 let the LLM be more creative, while values close to 0.0 let it be more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a variable called model with \"gpt-4o-mini\" as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a variable called temperature with some float \n",
    "# value ranging from 0.0 to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tell the model how to behave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most powerful parameter is system prompt. It enables you to instruct how you want the LLM to behave. It's important to write a clear, concise instruction for the LLM.\n",
    "\n",
    "- For this exercise, the prompt should be specific enough to guide the LLM towards the desired output (B2B content about CultPass)\n",
    "- But also flexible enough to handle a range of industries (target) and channels (email, instagram, tiktok...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a variable called system_prompt with \n",
    "# any instruction text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a function to reuse LLM calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have all the parameters, you need to accept the user input to send to OpenAI API.\n",
    "\n",
    "To accept it, add a new element to the `messages` list inside the `create_content` function. It's a dictionary similar to the first element, but this time the role is `user`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_content(query:str,\n",
    "                   client:OpenAI, \n",
    "                   system_prompt:str,\n",
    "                   model:str,\n",
    "                   temperature:float)->str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        # FILL IN - marketing analyst query\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    # Experiment returning the full response to understand the object\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Call `create_content` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marketing Analyst input\n",
    "analyst_query = \"Create an instagram post for clients in the automotive industry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = create_content(\n",
    "    query=analyst_query,\n",
    "    # FILL IN - pass the other arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Break things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understood how it works, experiment new things.\n",
    "\n",
    "- Change the temperature of the model\n",
    "- Change the system prompt\n",
    "- Change the user query to other channels and industries\n",
    "- Inspect the objects returned by OpenAI, what else you can get out of it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
