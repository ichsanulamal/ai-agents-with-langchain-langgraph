Welcome to your next step in building more advanced AI Agents! In this exercise, you’ll enhance your AI agent by adding self-reflection and memory. These features allow the agent to critique its responses iteratively, improving over time while maintaining a log of all interactions.

This mimics how human learning and feedback loops work, helping your agent refine its answers and avoid mistakes. By implementing this, you’ll push your agent towards more accurate and thoughtful outputs.

## Scenario

Imagine you’re working on an AI-powered chatbot that needs to provide high-quality, refined responses to users in a customer support system. Sometimes, AI-generated responses might miss context or lack clarity.

Your task is to upgrade your agent by:

- Enabling it to reflect on its responses before delivering them.
- Allowing iterative refinement to improve response quality.
- Keeping track of conversations for better context awareness.

By the end of this exercise, you’ll have an AI agent that learns from itself, identifies errors, and iteratively enhances its replies.

## Challenge
In this exercise, you are tasked with upgrading the existing Agent class by adding:

1. A memory layer to track previous interactions.
2. A self-reflection mechanism that critiques and refines responses.

Your agent should:

- Store conversation history for better decision-making.
- Critique its own responses using a structured feedback prompt.
- Refine its outputs iteratively, following predefined rules.

## Steps

1. Setup Your Environment
2. Add a Memory Layer
3. Update the Agent Class
4. Test some Self-Reflecting Agents
5. Experiment and Refine
