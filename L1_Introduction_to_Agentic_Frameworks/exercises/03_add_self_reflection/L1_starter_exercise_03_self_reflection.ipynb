{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Add Memory and Self-reflection - STARTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you’ll enhance your AI agent by adding self-reflection and memory. These features allow the agent to iteratively critique its responses and improve over time while maintaining a log of all interactions. \n",
    "\n",
    "This mimics how human learning and feedback loops work, pushing your agent towards more refined and accurate outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "In this exercise, you are tasked with upgrading the existing agent. This version can learn from its previous answers, identify mistakes, and refine its responses automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap: how to use OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"sk-\")\n",
    "```\n",
    "Usually the OpenAI API key is a long string starting with `sk-`.\n",
    "\n",
    "\n",
    "Alternatively, can do this implicitly. However to use this approach, you should have a .env file with a variable called OPENAI_API_KEY.\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "```\n",
    "\n",
    "Loading an environment variable prevents you from exposing it in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL IN - Instantiate your client\n",
    "client = OpenAI(\n",
    "    api_key = \"YOUR_API_KEY_HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer all user questions\"},\n",
    "            {\"role\": \"user\", \"content\":\"What have I asked?\"},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recap: Adding Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add reflection, you need to make sure your agent can keep  track of all interactions. Let's quickly recap how to do it with a simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = [\n",
    "    {\"role\": \"system\", \"content\": \"Answer all user questions\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's an API\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=memory,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "memory.append(\n",
    "    {\"role\": \"assistant\", \"content\": new_response.choices[0].message.content}\n",
    ")\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.append(\n",
    "    {\"role\": \"user\", \"content\": \"What have I asked?\"}\n",
    ")\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=memory,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "memory.append(\n",
    "    {\"role\": \"assistant\", \"content\": new_response.choices[0].message.content}\n",
    ")\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a memory layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you remember how to use a list of messages, it's recommended to have a proper class to deal with more complicated cases.\n",
    "\n",
    "Create the Memory class and add the necessary methods to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - Create your memory layer\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Update the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will enhance the AI Agent with self-reflection capabilities, allowing it to critique its own responses and refine them iteratively. This feature enables the agent to evaluate its output and improve the response quality before delivering a final answer.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "Your task is to modify the agent so that it can:\n",
    "\n",
    "- Store conversation history – Implement a memory mechanism to track interactions.\n",
    "- Generate an initial response – Process user input and return a response using the language model.\n",
    "- Critique its own response when enabled – If self-reflection is activated, the agent should generate feedback on its own answer.\n",
    "- Refine its response iteratively – Based on the self-critique, the agent should adjust its reply, improving clarity, accuracy, and relevance.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "- Implement a memory layer to retain conversation history.\n",
    "- Introduce a self-reflection mechanism that allows the agent to analyze its response and refine it.\n",
    "- Limit the number of self-reflection iterations to prevent excessive loops (minimum 1, maximum 3).\n",
    "- Ensure flexibility by allowing users to toggle self-reflection on or off.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- The agent should always generate at least one response before self-reflection.\n",
    "- If self-reflection is enabled, it should run at least once more to critique and improve its output.\n",
    "- The number of iterations should be controlled and not exceed three refinements.\n",
    "- Implement logging functionality (verbose mode) to track the refinement process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoke**\n",
    "\n",
    "Refactor `invoke()` method. This method now should include:\n",
    "- self_reflection paramenter (default: False);\n",
    "- max_iter parameter (default: 1);\n",
    "\n",
    "If self_reflection is set to True, it should use a loop to generate an initial response. Then critiquing and refining the response in subsequent iterations up to the number of iterations defined in max_iter.\n",
    "\n",
    "Use the self.memory to store each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules for self-reflection:\n",
    "\n",
    "- Don't allow values less than 1\n",
    "- Don't allow values greater than 3\n",
    "- Max iter is controlled by self_reflection flag. \n",
    "- If set to true, it needs to call the LLM at least once more for the criticism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - Create your critique prompt\n",
    "SELF_CRITIQUE_PROMPT = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"A self-reflection AI Agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name:str = \"Agent\", \n",
    "        role:str = \"Personal Assistant\",\n",
    "        instructions:str = \"Help users with any question\",\n",
    "        model:str = \"gpt-4o-mini\",\n",
    "        temperature:float = 0.0,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # FILL IN - Instantiate your client properly\n",
    "        self.client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "        # FILL IN - Create your memory layer\n",
    "        self.memory =\n",
    "\n",
    "        # FILL IN - Create your critique prompt\n",
    "        self.critique_prompt = \n",
    "\n",
    "    \n",
    "    def invoke(self, \n",
    "               message: str, \n",
    "               self_reflection: bool = False, \n",
    "               max_iter: int = 1) -> str:\n",
    "        # FILL IN - refactor the invoke method to add self-reflection\n",
    "        # Rules\n",
    "        # - Don't allow values less than 1\n",
    "        # - Don't allow values greater than 3\n",
    "        # - Max iter is controlled by self_reflection flag. \n",
    "        # - If set to true, it needs to call the LLM at least once more for the criticism\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build some agents and have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some specific agents and invoke them with self_reflection = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a default agent with role and instructions\n",
    "# Then ask it simple questions like:  \n",
    "# \"What is the capital of France?\"\n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a travel agent with role and instructions\n",
    "# Then ask it questions like:\n",
    "# Where should I go for vacation in December?\n",
    "travel_agent ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a math tutor agent with role and instructions\n",
    "# Then ask it questions like:\n",
    "# How do I solve a quadratic equation?\n",
    "math_tutor_agent ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a creative storyteller agent with role and instructions\n",
    "# Remember, the higher temperature the more creative it will be \n",
    "# Then ask it questions like:\n",
    "# Tell me a story about a dragon and a wizard\n",
    "storyteller_agent ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Break things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understood how it works, experiment new things.\n",
    "\n",
    "- Experiment new critique prompts\n",
    "- What happens when you increase the number of iterations?\n",
    "- Try adding an argument to invoke() method to inspect it (verbose=True)\n",
    "- What else can you try?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
