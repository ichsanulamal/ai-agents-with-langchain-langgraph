{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Enable Tool Calling - SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, youâ€™ll enhance your AI agent by adding tool-calling capabilities, allowing it to interact with external functions dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "Imagine you're building an AI-powered assistant that helps users with various tasks such as:\n",
    "\n",
    "- Fetching real-time stock prices\n",
    "- Performing complex calculations\n",
    "- Querying a weather API\n",
    "- Searching a database\n",
    "\n",
    "Instead of manually deciding when to call which function, your AI agent will automatically detect when a tool is needed and invoke it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import inspect\n",
    "import json\n",
    "from typing import (\n",
    "    TypedDict, \n",
    "    List, Dict, Literal, \n",
    "    Callable, Optional, Any, \n",
    "    get_type_hints\n",
    ")\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import ChatCompletionMessageToolCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap: how to use OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"sk-\")\n",
    "```\n",
    "Usually the OpenAI API key is a long string starting with `sk-`.\n",
    "\n",
    "\n",
    "Alternatively, can do this implicitly. However to use this approach, you should have a .env file with a variable called OPENAI_API_KEY.\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "```\n",
    "\n",
    "Loading an environment variable prevents you from exposing it in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL IN - Instantiate your client\n",
    "# client = OpenAI(\n",
    "#     api_key = \"YOUR_API_KEY_HERE\"\n",
    "# )\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm focused on Python programming, so I don't have information about the Java Virtual Machine or other programming languages. If you have any questions related to Python, feel free to ask!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"Act as Senior Python Programmer. You don't know anything about other programming language, so don't provide answers about languanges like like Java.\"\n",
    "user_question = \"What is the Java Virtual Machine?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_question},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recap: Memory & Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently we combined memory with custom Python functions to create the full cycle of tool calling, whic enabled an LLM to interact with the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self._messages: List[Dict[str, str]] = []\n",
    "    \n",
    "    def add_message(self, \n",
    "                    role: Literal['user', 'system', 'assistant', 'tool'], \n",
    "                    content: str,\n",
    "                    tool_calls: dict=dict(),\n",
    "                    tool_call_id=None)-> None:\n",
    "\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "        if role == \"tool\":\n",
    "            message = {\n",
    "                \"role\": role,\n",
    "                \"content\": content,\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "            }\n",
    "\n",
    "        self._messages.append(message)\n",
    "\n",
    "    def get_messages(self) -> List[Dict[str, str]]:\n",
    "        return self._messages\n",
    "\n",
    "    def last_message(self) -> None:\n",
    "        if self._messages:\n",
    "            return self._messages[-1]\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_tools(user_question:str=None, \n",
    "                    memory:Memory=None, \n",
    "                    model:str=\"gpt-4o-mini\", \n",
    "                    temperature=0.0, \n",
    "                    tools=None)-> str:\n",
    "    messages = [{\"role\": \"user\", \"content\": user_question}]\n",
    "    if memory:\n",
    "        if user_question:\n",
    "            memory.add_message(role=\"user\", content=user_question)\n",
    "        messages = memory.get_messages()        \n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        messages = messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    \n",
    "    ai_message = str(response.choices[0].message.content)\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "    \n",
    "    if memory:\n",
    "        memory.add_message(role=\"assistant\", content=ai_message, tool_calls=tool_calls)\n",
    "    \n",
    "    return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "    \n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"power\",\n",
    "        \"description\": \"Exponentatiation: base to the power of exponent\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"base\": {\"type\": \"number\"},\n",
    "                \"exponent\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"base\", \"exponent\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate memory and start with the system prompt\n",
    "memory = Memory()\n",
    "memory.add_message(role=\"system\", content=\"You're a helpful assitant\")\n",
    "\n",
    "# Call the LLM with a question that needs a tool\n",
    "ai_message = chat_with_tools(\n",
    "    \"2 to the power of -5?\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# Get the arguments from the tool_calls object and call the actual defined function\n",
    "args = json.loads(memory.last_message()['tool_calls'][0].function.arguments)\n",
    "result = power(args[\"base\"], args[\"exponent\"])\n",
    "\n",
    "# Extract the tool_call_id and feed the LLM with the result from the function \n",
    "tool_call_id = memory.last_message()['tool_calls'][0].id\n",
    "memory.add_message(role=\"tool\", content=str(result), tool_call_id=tool_call_id)\n",
    "ai_message = chat_with_tools(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}},\n",
       " {'role': 'user', 'content': '2 to the power of -5?', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': 'None',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_zmt0wLamDtj1Tf0DlYNd9zvU', function=Function(arguments='{\"base\":2,\"exponent\":-5}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '0.03125',\n",
       "  'tool_call_id': 'call_zmt0wLamDtj1Tf0DlYNd9zvU'},\n",
       " {'role': 'assistant',\n",
       "  'content': '2 to the power of -5 is 0.03125.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Tool abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although powerful, the way we've built by calling manually is prone to errors. What if you don't pass the correct type or miss one required field in the json-schema?\n",
    "\n",
    "Your task is creating an abstraction to make it easier to build a tool and call it. \n",
    "\n",
    "Tip: Inspect the json schema of the tool we created to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your class should have at least the following methods: \n",
    "- `__init__()` receiving the function and some logic to extract docs, arguments and their types\n",
    "- `dict()` to return the json schema\n",
    "- `__call__()` to enable the object instantiated to be callable. \n",
    "\n",
    "Example:\n",
    "```python\n",
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        self.func = func\n",
    "    \n",
    "    def dict(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)  \n",
    "\n",
    "def my_func(arg1:int)->str:\n",
    "    return \"ok\"\n",
    "\n",
    "my_tool = Tool(my_func)\n",
    "my_tool(arg1=1)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        ## FILL IN - Create logic to extract the docs, the arguments and their types\n",
    "        self.func = func\n",
    "        self.name = func.__name__\n",
    "        self.description = func.__doc__\n",
    "        self.argument_types_map = get_type_hints(func)\n",
    "        self.signature = inspect.signature(func)\n",
    "        self.arguments = [\n",
    "            {\n",
    "                \"name\": key, \n",
    "                \"type\": self._infer_json_schema_type(value),\n",
    "                \"required\": param.default == inspect.Parameter.empty\n",
    "            } \n",
    "            for key, value in self.argument_types_map.items()\n",
    "            if (param := self.signature.parameters.get(key))\n",
    "        ]\n",
    "\n",
    "    def dict(self):\n",
    "        ## FILL IN - Return the appropriate json schema\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parallel_tool_calls\": False,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        argument[\"name\"]: {\n",
    "                            \"type\": argument[\"type\"],\n",
    "                        }\n",
    "                        for argument in self.arguments\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        argument[\"name\"] \n",
    "                        for argument in self.arguments \n",
    "                        if argument[\"required\"]\n",
    "                    ],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    \n",
    "    def _infer_json_schema_type(self, arg_type: Any) -> str:\n",
    "        if arg_type == bool:\n",
    "            return \"boolean\"\n",
    "        elif arg_type == int:\n",
    "            return \"integer\"\n",
    "        elif arg_type == float:\n",
    "            return \"number\"\n",
    "        elif arg_type == str:\n",
    "            return \"string\"\n",
    "        elif arg_type == list:\n",
    "            return \"array\"\n",
    "        elif arg_type == dict:\n",
    "            return \"object\"\n",
    "        elif arg_type is None:\n",
    "            return \"null\"\n",
    "        elif arg_type == datetime.date or arg_type == datetime.datetime:\n",
    "            return \"string\"  # JSON Schema treats dates as strings\n",
    "        else:\n",
    "            return \"string\"  # Default to string if type is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_tool = Tool(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'power',\n",
       "  'description': 'Exponentatiation: base to the power of exponent',\n",
       "  'parallel_tool_calls': False,\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'base': {'type': 'number'}, 'exponent': {'type': 'number'}},\n",
       "   'required': ['base', 'exponent'],\n",
       "   'additionalProperties': False},\n",
       "  'strict': True}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_tool.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_tool(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Update the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will enhance the logic of your agent so that it can handle user queries and interact with external tools dynamically. The goal is to refine how the agent processes user messages, generates responses, and invokes tools when necessary.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "You will modify the logic responsible for:\n",
    "\n",
    "- Processing user input â€“ The agent should record and manage conversation history.\n",
    "- Generating a response â€“ The agent will use a language model to create a reply based on previous messages.\n",
    "- Identifying when tools are needed â€“ If a tool is required to complete the request, the agent should detect this and trigger the appropriate function.\n",
    "- Handling tool execution and responses â€“ The agent should execute the tool, capture its output, and integrate the result into the conversation.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "- Update the logic to check whether a tool needs to be invoked based on the AI-generated response.\n",
    "- If tools are needed, execute them with the correct arguments.\n",
    "- Incorporate tool results into the conversation so that the AI can refine its response using the additional information.\n",
    "- Ensure the agent can handle multiple tool calls recursively, meaning if the response suggests using another tool after the first one, it should be processed correctly.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- Think about how the agent decides when to call a tool.\n",
    "- Ensure the agent stores the toolâ€™s response correctly so it can continue the conversation naturally.\n",
    "- Handle cases where multiple tools might need to be used in sequence before the final response is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"A tool-calling AI Agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name:str = \"Agent\", \n",
    "        role:str = \"Personal Assistant\",\n",
    "        instructions:str = \"Help users with any question\",\n",
    "        model:str = \"gpt-4o-mini\",\n",
    "        temperature:float = 0.0,\n",
    "        tools:List[Tool] = [],\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.memory = Memory()\n",
    "        self.memory.add_message(\n",
    "            role=\"system\",\n",
    "            content=f\"You're an AI Agent, your role is {self.role}, \" \n",
    "                    f\"and you need to {self.instructions}\",\n",
    "        )\n",
    "\n",
    "        # FILL IN - Instantiate your client properly\n",
    "        self.client = OpenAI()\n",
    "\n",
    "        # FILL IN - Create your tool\n",
    "        self.tools = tools\n",
    "        self.tool_map = {t.name:t for t in tools}\n",
    "        self.openai_tools = [t.dict() for t in self.tools] if self.tools else None\n",
    "\n",
    "    def invoke(self, user_message: str) -> str:\n",
    "        # FILL IN - refactor the invoke method to add tool calling\n",
    "        self.memory.add_message(\n",
    "            role=\"user\",\n",
    "            content=user_message,\n",
    "        )\n",
    "\n",
    "        ai_message = self._get_completion(\n",
    "            messages = self.memory.get_messages(),\n",
    "        )\n",
    "\n",
    "        tool_calls = ai_message.tool_calls\n",
    "        self.memory.add_message(\n",
    "            role=\"assistant\",\n",
    "            content=ai_message.content,\n",
    "            tool_calls=tool_calls,\n",
    "        )\n",
    "\n",
    "        if tool_calls:\n",
    "            self._call_tools(tool_calls)\n",
    "            \n",
    "        return self.memory.last_message()\n",
    "\n",
    "    def _call_tools(self, tool_calls:List[ChatCompletionMessageToolCall]):\n",
    "        for t in tool_calls:\n",
    "            tool_call_id = t.id\n",
    "            function_name = t.function.name\n",
    "            args = json.loads(t.function.arguments)\n",
    "            callable_tool = self.tool_map[function_name]\n",
    "            result = callable_tool(**args)\n",
    "            self.memory.add_message(\n",
    "                role=\"tool\", \n",
    "                content=str(result), \n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "\n",
    "        ai_message = self._get_completion(\n",
    "            messages = self.memory.get_messages(),\n",
    "        )\n",
    "\n",
    "        tool_calls = ai_message.tool_calls\n",
    "\n",
    "        self.memory.add_message(\n",
    "            role=\"assistant\",\n",
    "            content=ai_message.content,\n",
    "            tool_calls=tool_calls,\n",
    "        )\n",
    "\n",
    "        if tool_calls:\n",
    "            self._call_tools(tool_calls)\n",
    "\n",
    "\n",
    "    def _get_completion(self, messages:List[Dict])-> ChatCompletionMessage:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            messages=messages,\n",
    "            tools=self.openai_tools,\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build some agents and have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some specific agents with  tools, invoke then and  inspect their memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - create a default agent\n",
    "agent = Agent(\n",
    "    tools=[Tool(power)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '10 + 5 equals 15.', 'tool_calls': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN - Ask it simple questions not related to the tools you created:  \n",
    "# \"What is 10 + 5?\"\n",
    "agent.invoke(\"What is 10 + 5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is 10 + 5?', 'tool_calls': {}},\n",
       " {'role': 'assistant', 'content': '10 + 5 equals 15.', 'tool_calls': None}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN - Check its memory\n",
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - Reset your agent's memory\n",
    "agent.memory.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '2 to the power of 3 is 8.',\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN - Ask it simple questions related to the tools you created:  \n",
    "# \"What is 2 to the power of 3\"\n",
    "agent.invoke(\"What is 2 to the power of 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is 2 to the power of 3', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_71T7xayvhDt6fes4YpjbapH1', function=Function(arguments='{\"base\":2,\"exponent\":3}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '8',\n",
       "  'tool_call_id': 'call_71T7xayvhDt6fes4YpjbapH1'},\n",
       " {'role': 'assistant',\n",
       "  'content': '2 to the power of 3 is 8.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN - Check its memory\n",
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '3 to the power of (2 to the power of 2) is 81.',\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN - Ask it harder questions related to the tools you created:  \n",
    "# What is 3 to the power of (2 to the power of 2)?\n",
    "agent.invoke(\"What is 3 to the power of (2 to the power of 2)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is 2 to the power of 3', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_71T7xayvhDt6fes4YpjbapH1', function=Function(arguments='{\"base\":2,\"exponent\":3}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '8',\n",
       "  'tool_call_id': 'call_71T7xayvhDt6fes4YpjbapH1'},\n",
       " {'role': 'assistant',\n",
       "  'content': '2 to the power of 3 is 8.',\n",
       "  'tool_calls': None},\n",
       " {'role': 'user',\n",
       "  'content': 'What is 3 to the power of (2 to the power of 2)?',\n",
       "  'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_9EFaTaJvPCU07Y5WsA88j1gu', function=Function(arguments='{\"base\": 2, \"exponent\": 2}', name='power'), type='function'),\n",
       "   ChatCompletionMessageToolCall(id='call_LVdbyU0a7tMPnZxfdCKt2ds3', function=Function(arguments='{\"base\": 3, \"exponent\": 0}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '4',\n",
       "  'tool_call_id': 'call_9EFaTaJvPCU07Y5WsA88j1gu'},\n",
       " {'role': 'tool',\n",
       "  'content': '1',\n",
       "  'tool_call_id': 'call_LVdbyU0a7tMPnZxfdCKt2ds3'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_OYH1inIZJs0ChdGcdiPoNpEB', function=Function(arguments='{\"base\":3,\"exponent\":4}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '81',\n",
       "  'tool_call_id': 'call_OYH1inIZJs0ChdGcdiPoNpEB'},\n",
       " {'role': 'assistant',\n",
       "  'content': '3 to the power of (2 to the power of 2) is 81.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILL IN - Check its memory\n",
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Break things\n",
    "\n",
    "Now that you understood how it works, experiment new things.\n",
    "\n",
    "- Experiment new critique prompts\n",
    "- What happens when you increase the number of iterations?\n",
    "- Try accessing the memory to inspect it (agent.memory) instead of reading the outputs (verbose=False)\n",
    "- What else can you try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
