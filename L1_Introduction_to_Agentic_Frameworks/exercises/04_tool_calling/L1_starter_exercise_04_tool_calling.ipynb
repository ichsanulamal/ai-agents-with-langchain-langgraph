{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Enable Tool Calling - STARTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, youâ€™ll enhance your AI agent by adding tool-calling capabilities, allowing it to interact with external functions dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "Imagine you're building an AI-powered assistant that helps users with various tasks such as:\n",
    "\n",
    "- Fetching real-time stock prices\n",
    "- Performing complex calculations\n",
    "- Querying a weather API\n",
    "- Searching a database\n",
    "\n",
    "Instead of manually deciding when to call which function, your AI agent will automatically detect when a tool is needed and invoke it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import inspect\n",
    "import json\n",
    "from typing import (\n",
    "    TypedDict, \n",
    "    List, Dict, Literal, \n",
    "    Callable, Optional, Any, \n",
    "    get_type_hints\n",
    ")\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import ChatCompletionMessageToolCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap: how to use OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"voc-\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Instantiate your client\n",
    "client = OpenAI(\n",
    "    api_key = \"YOUR_API_KEY_HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Act as Senior Python Programmer. You don't know anything about other programming language, so don't provide answers about languanges like like Java.\"\n",
    "user_question = \"What is the Java Virtual Machine?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_question},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recap: Memory & Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently we combined memory with custom Python functions to create the full cycle of tool calling, which enabled an LLM to interact with the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self._messages: List[Dict[str, str]] = []\n",
    "    \n",
    "    def add_message(self, \n",
    "                    role: Literal['user', 'system', 'assistant', 'tool'], \n",
    "                    content: str,\n",
    "                    tool_calls: dict=dict(),\n",
    "                    tool_call_id=None)-> None:\n",
    "\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "        if role == \"tool\":\n",
    "            message = {\n",
    "                \"role\": role,\n",
    "                \"content\": content,\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "            }\n",
    "\n",
    "        self._messages.append(message)\n",
    "\n",
    "    def get_messages(self) -> List[Dict[str, str]]:\n",
    "        return self._messages\n",
    "\n",
    "    def last_message(self) -> None:\n",
    "        if self._messages:\n",
    "            return self._messages[-1]\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_tools(user_question:str=None, \n",
    "                    memory:Memory=None, \n",
    "                    model:str=\"gpt-4o-mini\", \n",
    "                    temperature=0.0, \n",
    "                    tools=None)-> str:\n",
    "    messages = [{\"role\": \"user\", \"content\": user_question}]\n",
    "    if memory:\n",
    "        if user_question:\n",
    "            memory.add_message(role=\"user\", content=user_question)\n",
    "        messages = memory.get_messages()        \n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        messages = messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    \n",
    "    ai_message = str(response.choices[0].message.content)\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "    \n",
    "    if memory:\n",
    "        memory.add_message(role=\"assistant\", content=ai_message, tool_calls=tool_calls)\n",
    "    \n",
    "    return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "    \n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"power\",\n",
    "        \"description\": \"Exponentatiation: base to the power of exponent\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"base\": {\"type\": \"number\"},\n",
    "                \"exponent\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"base\", \"exponent\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate memory and start with the system prompt\n",
    "memory = Memory()\n",
    "memory.add_message(role=\"system\", content=\"You're a helpful assitant\")\n",
    "\n",
    "# Call the LLM with a question that needs a tool\n",
    "ai_message = chat_with_tools(\n",
    "    \"2 to the power of -5?\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# Get the arguments from the tool_calls object and call the actual defined function\n",
    "args = json.loads(memory.last_message()['tool_calls'][0].function.arguments)\n",
    "result = power(args[\"base\"], args[\"exponent\"])\n",
    "\n",
    "# Extract the tool_call_id and feed the LLM with the result from the function \n",
    "tool_call_id = memory.last_message()['tool_calls'][0].id\n",
    "memory.add_message(role=\"tool\", content=str(result), tool_call_id=tool_call_id)\n",
    "ai_message = chat_with_tools(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Tool abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although powerful, the way we've built by calling manually is prone to errors. What if you don't pass the correct type or miss one required field in the json-schema?\n",
    "\n",
    "Your task is creating an abstraction to make it easier to build a tool and call it. \n",
    "\n",
    "Tip: Inspect the json schema of the tool we created to help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your class should have at least the following methods: \n",
    "- `__init__()` receiving the function and some logic to extract docs, arguments and their types\n",
    "- `dict()` to return the json schema\n",
    "- `__call__()` to enable the object instantiated to be callable. \n",
    "\n",
    "Example:\n",
    "```python\n",
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        self.func = func\n",
    "    \n",
    "    def dict(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)  \n",
    "\n",
    "def my_func(arg1:int)->str:\n",
    "    return \"ok\"\n",
    "\n",
    "my_tool = Tool(my_func)\n",
    "my_tool(arg1=1)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important learn about the following Python methods to understand how to parse functions and get docstrings, arguments and types:\n",
    "- typing.get_type_hints()\n",
    "- inspect.signature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        # TODO  - Create logic to extract the docs, the arguments and their types\n",
    "        self.func = func\n",
    "\n",
    "    def dict(self):\n",
    "        # TODO  - Return the appropriate json schema\n",
    "        pass\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "    \n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_tool = Tool(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_tool.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_tool(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Update the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will enhance the logic of your agent so that it can handle user queries and interact with external tools dynamically. The goal is to refine how the agent processes user messages, generates responses, and invokes tools when necessary.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "You will modify the logic responsible for:\n",
    "\n",
    "- Processing user input â€“ The agent should record and manage conversation history.\n",
    "- Generating a response â€“ The agent will use a language model to create a reply based on previous messages.\n",
    "- Identifying when tools are needed â€“ If a tool is required to complete the request, the agent should detect this and trigger the appropriate function.\n",
    "- Handling tool execution and responses â€“ The agent should execute the tool, capture its output, and integrate the result into the conversation.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "- Update the logic to check whether a tool needs to be invoked based on the AI-generated response.\n",
    "- If tools are needed, execute them with the correct arguments.\n",
    "- Incorporate tool results into the conversation so that the AI can refine its response using the additional information.\n",
    "- Ensure the agent can handle multiple tool calls recursively, meaning if the response suggests using another tool after the first one, it should be processed correctly.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- Think about how the agent decides when to call a tool.\n",
    "- Ensure the agent stores the toolâ€™s response correctly so it can continue the conversation naturally.\n",
    "- Handle cases where multiple tools might need to be used in sequence before the final response is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"A tool-calling AI Agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name:str = \"Agent\", \n",
    "        role:str = \"Personal Assistant\",\n",
    "        instructions:str = \"Help users with any question\",\n",
    "        model:str = \"gpt-4o-mini\",\n",
    "        temperature:float = 0.0,\n",
    "        tools:List[Tool] = [],\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.memory = Memory()\n",
    "        self.memory.add_message(\n",
    "            role=\"system\",\n",
    "            content=f\"You're an AI Agent, your role is {self.role}, \" \n",
    "                    f\"and you need to {self.instructions}\",\n",
    "        )\n",
    "\n",
    "        # TODO  - Instantiate your client properly\n",
    "        self.client = OpenAI()\n",
    "\n",
    "        # TODO  - Create your tool\n",
    "        self.tools = \n",
    "\n",
    "    def invoke(self, user_message: str) -> str:\n",
    "        # TODO - refactor the invoke method to add tool calling\n",
    "            \n",
    "        return self.memory.last_message()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build some agents and have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some specific agents with  tools, invoke then and  inspect their memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO  - Create a default agent passing the tools you created\n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Ask it simple questions not related to the tools you created:  \n",
    "# Example: \"What is 10 + 5?\"\n",
    "agent.invoke(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Check its memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Reset your agent's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Ask it simple questions related to the tools you created:  \n",
    "# \"What is 2 to the power of 3\"\n",
    "agent.invoke(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Check its memory again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Ask it harder questions related to the tools you created:  \n",
    "# What is 3 to the power of (2 to the power of 2)?\n",
    "agent.invoke(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Check its memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment\n",
    "\n",
    "Now that you understood how it works, experiment with new things.\n",
    "\n",
    "- Experiment new critique prompts\n",
    "- What happens when you increase the number of iterations?\n",
    "- Try accessing the memory to inspect it (agent.memory) instead of reading the outputs (verbose=False)\n",
    "- What else can you try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
