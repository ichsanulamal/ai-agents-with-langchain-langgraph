{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Create a Text2SQL Agent - STARTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you’ll build an AI agent capable of converting natural language questions into SQL queries, executing them, and returning the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "You’re building a Text2SQL assistant for a Sales Dashboard.\n",
    "The agent should:\n",
    "\n",
    "- Parse user questions.\n",
    "- Identify the relevant tables and columns.\n",
    "- Generate the corresponding SQL query.\n",
    "- Execute the query and return the result.\n",
    "\n",
    "This enables non-technical users to ask questions in plain English and get data insights without writing SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sql_toolkit import (\n",
    "    list_tables_tool, \n",
    "    get_table_schema_tool, \n",
    "    execute_sql_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate Chat Model with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an ChatOpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    api_key=\"voc-\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Instantiate your chat model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    api_key = \"YOUR_API_KEY_HERE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the State Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either chose from creating it with TypedDict, Pydantic or using the MessagesState. It should store:\n",
    "\n",
    "- user_query: The user's natural language question.\n",
    "- messages: The conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Instantiate your workflow passing a State Schema\n",
    "workflow = StateGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the tools available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the following tools:\n",
    "- list_tables_tool: Lists tables in the database., \n",
    "- get_table_schema_tool: Retrieves the schema of a specific table, \n",
    "- execute_sql_tool: Executes the generated SQL query.\n",
    "\n",
    "They are all accessible in the sql_toolkit.py. It's already imported. You need to add them to the tools list, then add the tools list to a node and bind the tools to the llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - create a list with the tools\n",
    "dba_tools = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"dba_tools\", ToolNode(dba_tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dba_llm = llm.bind_tools(dba_tools, tool_choice=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The agent node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the dba_agent node, you need to build the initial messages to start the conversation. So, we'll first create the messages builder node.\n",
    "\n",
    "The llm you'll use has already the tools bound to it, so the message will have a content or a tool_calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_builder(state: State):\n",
    "    dba_sys_msg = (\n",
    "        \"You are a Sr. SQL developer tasked with generating SQL queries. Perform the following steps:\\n\"\n",
    "        \"First, find out the appropriate table name based on all tables. \"\n",
    "        \"Then get the table's schema to understand the columns. \"\n",
    "        \"With the table name and the schema, generate the ANSI SQL query you think is applicable to the user question. \"\n",
    "        \"Finally, use a tool to execute the above SQL query and output the result based on the user question.\"\n",
    "    )\n",
    "    messages = [\n",
    "        SystemMessage(dba_sys_msg),\n",
    "        HumanMessage(state[\"user_query\"])\n",
    "    ]\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dba_agent(state: State):\n",
    "   ai_message = dba_llm.invoke(state[\"messages\"])\n",
    "   ai_message.name = \"dba_agent\"\n",
    "   return {\"messages\": ai_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Add both nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable the cycle, you need to have a routing function. This function:\n",
    "\n",
    "- Inspects the conversation history.\n",
    "- Decides whether to call a tool or end the workflow.\n",
    "\n",
    "Then, create the nodes:\n",
    "- After the START entrypoint, you need to move to messages_builder\n",
    "- From messages_builder, to the dba_agent\n",
    "- The dba_agent should call the routing_function within a conditional edge\n",
    "- If the response is a tool_call, send to dba_tools node\n",
    "- Else, terminates in the END termination node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Your conditional function to route between dba_tools or END\n",
    "def should_continue(state: State):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(START, \"messages_builder\")\n",
    "workflow.add_edge(\"messages_builder\", \"dba_agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"dba_agent\", \n",
    "    path=should_continue, \n",
    "    path_map=[\"dba_tools\", END]\n",
    ")\n",
    "workflow.add_edge(\"dba_tools\", \"dba_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compile and Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile your graph, display it and run for inputs and config passed in the invoke() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        react_graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_engine = create_engine(f\"sqlite:///sales.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"db_engine\": db_engine\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ask the followin question:\n",
    "# \"How many Dell XPS 15 were sold?\"\n",
    "inputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pass input and config arguments\n",
    "messages = react_graph.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understood how it works, experiment with new things.\n",
    "- Use the tools to understand what you have in the sales.db\n",
    "- Ask other questions to it\n",
    "- Use your own database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
