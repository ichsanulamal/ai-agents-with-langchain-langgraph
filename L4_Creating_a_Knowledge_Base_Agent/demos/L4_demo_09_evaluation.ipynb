{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henriquesantana/Projects/Udacity/agents/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "import requests\n",
    "from tavily import TavilyClient\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage, \n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState, add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv\n",
    "from ragas import EvaluationDataset\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from ragas import messages as ragas_messages\n",
    "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
    "from ragas.dataset_schema import MultiTurnSample\n",
    "from ragas.metrics import ToolCallAccuracy\n",
    "from ragas.metrics import AgentGoalAccuracyWithReference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "        metadata={\"company\":\"Meta\", \"topic\": \"llama\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "        metadata={\"company\":\"Nvidia\", \"topic\": \"acquisition\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Google is bringing Gemini to all older Pixel Buds\",\n",
    "        metadata={\"company\":\"Google\", \"topic\": \"gemini\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The first Intel Battlmage GPU benchmarks have leaked\",\n",
    "        metadata={\"company\":\"Intel\", \"topic\": \"gpu\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Dell partners with Nvidia to accelerate AI adoption in telecoms\",\n",
    "        metadata={\"company\":\"Dell\", \"topic\": \"partnership\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "ids = [\"id1\", \"id2\", \"id3\", \"id4\", \"id5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"udacity\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=ids)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(relevant_docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dell is partnering with Nvidia.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is partnering with Nvidia?\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "chain.invoke({\"context\": format_docs(relevant_docs), \"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ragas Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    \"What is Meta's latest development in AI?\",\n",
    "    \"Which company did Nvidia acquire?\",\n",
    "    \"What AI feature is Google adding to older Pixel Buds?\",\n",
    "    \"What recent information has leaked about Intel GPUs?\",\n",
    "    \"Which company did Dell partner with to accelerate AI adoption?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_responses = [\n",
    "    \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "    \"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "    \"Google is bringing Gemini to all older Pixel Buds\",\n",
    "    \"The first Intel Battlemage GPU benchmarks have leaked\",\n",
    "    \"Dell partners with Nvidia to accelerate AI adoption in telecoms\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for query, reference in zip(sample_queries, expected_responses):\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"context\": format_docs(relevant_docs), \n",
    "            \"query\": query\n",
    "        }\n",
    "    )\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\": query,\n",
    "            \"retrieved_contexts\": [doc.page_content for doc in relevant_docs],\n",
    "            \"response\": response,\n",
    "            \"reference\": reference,\n",
    "        }\n",
    "    )\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:14<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],\n",
    "    llm=evaluator_llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_recall': 1.0000, 'faithfulness': 1.0000, 'factual_correctness(mode=f1)': 0.5400}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangGraph workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_types_map = {\n",
    "    \"pikachu\": \"electric\",\n",
    "    \"eevee\": \"normal\",\n",
    "    \"bulbasaur\": \"grass/poison\",\n",
    "    \"squirtle\": \"water\",\n",
    "    \"charizard\": \"fire/flying\",\n",
    "    \"jigglypuff\": \"normal/fairy\",\n",
    "    \"meowth\": \"normal\",\n",
    "    \"psyduck\": \"water\",\n",
    "    \"machamp\": \"fighting\",\n",
    "    \"gengar\": \"ghost/poison\",\n",
    "    \"alakazam\": \"psychic\",\n",
    "    \"snorlax\": \"normal\",\n",
    "    \"dragonite\": \"dragon/flying\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_pokemon_type(pokemon_name: str) -> str:\n",
    "    \"\"\"Fetches the type of the specified Pokémon.\n",
    "\n",
    "    Args:\n",
    "        pokemon_name : The name of the Pokémon (e.g., 'pikachu', 'charizard', 'eevee').\n",
    "\n",
    "    Returns:\n",
    "        str: The type(s) of the Pokémon.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the specified Pokémon is not found in the data source.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pokemon_name = pokemon_name.lower().strip()\n",
    "        if pokemon_name not in pokemon_types_map:\n",
    "            raise KeyError(\n",
    "                f\"Pokémon '{pokemon_name}' not found. Available Pokémon: {', '.join(pokemon_types.keys())}\"\n",
    "            )\n",
    "        return pokemon_types_map[pokemon_name]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error fetching Pokémon type: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_pokemon_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: MessagesState):\n",
    "    ai_message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": ai_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"agent\", \n",
    "    path=router, \n",
    "    path_map=[\"tools\", END]\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = workflow.compile()\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the Gengar's type?\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting to Ragas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_trace = convert_to_ragas_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Tool Use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference_tool_calls=[\n",
    "        ragas_messages.ToolCall(\n",
    "            name=\"get_pokemon_type\", \n",
    "            args={\"pokemon_name\": \"gengar\"}\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = ToolCallAccuracy()\n",
    "scorer.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await scorer.multi_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Agent Goal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = MultiTurnSample(\n",
    "    user_input=ragas_trace,\n",
    "    reference=\"What is the Gengar's type?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = AgentGoalAccuracyWithReference()\n",
    "scorer.llm = LangchainLLMWrapper(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await scorer.multi_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
